{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inZF5rjGWTlO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction import text\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"netflixData.csv.zip\")\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5AMT8HWYYrJ",
        "outputId": "dfb9711f-75f1-4ae8-9002-f8754184ce10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                Show Id                          Title  \\\n",
            "0  cc1b6ed9-cf9e-4057-8303-34577fb54477                       (Un)Well   \n",
            "1  e2ef4e91-fb25-42ab-b485-be8e3b23dedb                         #Alive   \n",
            "2  b01b73b7-81f6-47a7-86d8-acb63080d525  #AnneFrank - Parallel Stories   \n",
            "3  b6611af0-f53c-4a08-9ffa-9716dc57eb9c                       #blackAF   \n",
            "4  7f2d4170-bab8-4d75-adc2-197f7124c070               #cats_the_mewvie   \n",
            "\n",
            "                                         Description  \\\n",
            "0  This docuseries takes a deep dive into the luc...   \n",
            "1  As a grisly virus rampages a city, a lone man ...   \n",
            "2  Through her diary, Anne Frank's story is retol...   \n",
            "3  Kenya Barris and his family navigate relations...   \n",
            "4  This pawesome documentary explores how our fel...   \n",
            "\n",
            "                      Director  \\\n",
            "0                          NaN   \n",
            "1                       Cho Il   \n",
            "2  Sabina Fedeli, Anna Migotto   \n",
            "3                          NaN   \n",
            "4             Michael Margolis   \n",
            "\n",
            "                                           Genres  \\\n",
            "0                                      Reality TV   \n",
            "1  Horror Movies, International Movies, Thrillers   \n",
            "2             Documentaries, International Movies   \n",
            "3                                     TV Comedies   \n",
            "4             Documentaries, International Movies   \n",
            "\n",
            "                                                Cast Production Country  \\\n",
            "0                                                NaN      United States   \n",
            "1                           Yoo Ah-in, Park Shin-hye        South Korea   \n",
            "2                        Helen Mirren, Gengher Gatti              Italy   \n",
            "3  Kenya Barris, Rashida Jones, Iman Benson, Genn...      United States   \n",
            "4                                                NaN             Canada   \n",
            "\n",
            "   Release Date Rating  Duration Imdb Score Content Type         Date Added  \n",
            "0        2020.0  TV-MA  1 Season     6.6/10      TV Show                NaN  \n",
            "1        2020.0  TV-MA    99 min     6.2/10        Movie  September 8, 2020  \n",
            "2        2019.0  TV-14    95 min     6.4/10        Movie       July 1, 2020  \n",
            "3        2020.0  TV-MA  1 Season     6.6/10      TV Show                NaN  \n",
            "4        2020.0  TV-14    90 min     5.1/10        Movie   February 5, 2020  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSB78KPVmyoB",
        "outputId": "ae87f077-37c9-4034-fcbd-3433994969d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5967, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7PEkIn1m6sK",
        "outputId": "f7c0b956-6a87-4887-c2f3-74eba9405f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Show Id                  0\n",
            "Title                    0\n",
            "Description              0\n",
            "Director              2064\n",
            "Genres                   0\n",
            "Cast                   530\n",
            "Production Country     559\n",
            "Release Date             3\n",
            "Rating                   4\n",
            "Duration                 3\n",
            "Imdb Score             608\n",
            "Content Type             0\n",
            "Date Added            1335\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[[\"Title\", \"Description\", \"Content Type\", \"Genres\"]] # slicing of the data set"
      ],
      "metadata": {
        "id": "osa8UHaYnKA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.isnull().sum())# we wont have null in the dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z30bDEGIr6UF",
        "outputId": "79a67f55-ec64-4add-d33a-6185a6db6d55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title           0\n",
            "Description     0\n",
            "Content Type    0\n",
            "Genres          0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Dp7AQL2urVk",
        "outputId": "d62f33fb-5251-45ed-d3bd-59439399e390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk # NLP Library ,help to remove garbage words\n",
        "import re # helps to create rules\n",
        "nltk.download('stopwords')\n",
        "stemmer = nltk.SnowballStemmer('english')\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "stopword=set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qV4gEKWKspEQ",
        "outputId": "6dde8e10-ddac-4d02-9bcf-615b282e5351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean(text):\n",
        "  text = str(text).lower()\n",
        "  text = re.sub('\\[.*?\\]', '', text)\n",
        "  text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "  text = re.sub('<.*?>+', '', text)\n",
        "  text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "  text = re.sub('\\n', '', text)\n",
        "  text = re.sub('\\w*\\d\\w*', '', text)\n",
        "  text = [word for word in text.split(' ') if word not in stopword]\n",
        "  text=\" \".join(text)\n",
        "  return text\n",
        "\n",
        "\n",
        "\n",
        "data[\"Title\"] = data[\"Title\"].apply(clean)"
      ],
      "metadata": {
        "id": "wc4WCyGr364i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[\"Title\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEKQ9BBp8oee",
        "outputId": "4c3b551f-8a0c-4048-92ad-f29f85c786ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                            unwell\n",
            "1                             alive\n",
            "2       annefrank  parallel stories\n",
            "3                           blackaf\n",
            "4                     catsthemewvie\n",
            "                   ...             \n",
            "5962                      الف مبروك\n",
            "5963                   دفعة القاهرة\n",
            "5964                           海的儿子\n",
            "5965                        반드시 잡는다\n",
            "5966             최강전사 미니특공대  영웅의 탄생\n",
            "Name: Title, Length: 5967, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer #IT WILL CONVERT THE DATSET INTO VECTORS AND TELL US MORE COMMON AND LESS COMMON VECTOR\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ],
      "metadata": {
        "id": "JBs0OmYiEQXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature = data['Genres'].tolist()\n",
        "tfidf = TfidfVectorizer(stop_words= \"english\")#makes garbage vectors together important vectors together\n",
        "tfidf_matrix = tfidf.fit_transform(feature)\n",
        "similarity = cosine_similarity(tfidf_matrix)# maps all of their distances together\n",
        "indices = pd.Series(data.index, index=data['Title']).drop_duplicates()"
      ],
      "metadata": {
        "id": "d1RDJfMNHtMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Optional: Create a function to get recommendations based on cosine similarity\n",
        "def get_recommendations(title, cosine_sim=similarity):\n",
        "    idx = indices[title]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:11]  # Get top 10 recommendations\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "    return data['Title'].iloc[movie_indices]\n",
        "\n"
      ],
      "metadata": {
        "id": "ggLbprKvMk_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "example_title = \"alive\"\n",
        "if example_title in indices:\n",
        "    print(get_recommendations(example_title))\n",
        "else:\n",
        "    print(f\"Title '{example_title}' not found in the dataset.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H303sFsTOBRR",
        "outputId": "d6b34669-792a-4358-9f74-97c624d07d76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "178                  aaviri\n",
            "360            andhaghaaram\n",
            "361             andhakaaram\n",
            "398                 apostle\n",
            "1759     game hindi version\n",
            "1760     game tamil version\n",
            "1761    game telugu version\n",
            "1801              ghost lab\n",
            "1804          ghost stories\n",
            "2104             homunculus\n",
            "Name: Title, dtype: object\n"
          ]
        }
      ]
    }
  ]
}